<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <!-- 
      The {page-title} parameters will be replaced with the 
      document title extracted from the <h1> element or
      file name, if there is no <h1> heading
    -->
    <title>Gradient Descent
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Atılım Güneş Baydin, Barak A. Pearlmutter and DiffSharp contributors">
    <meta name="description" content="DiffSharp is an automatic differentiation (AD) library implemented in the F# language by Atılım Güneş Baydin and Barak A. Pearlmutter, mainly for research applications in machine learning, as part of their work at the Brain and Computation Lab, Hamilton Institute, National University of Ireland Maynooth.">

    <script src="https://code.jquery.com/jquery-1.8.0.js"></script>
    <script src="https://code.jquery.com/ui/1.8.23/jquery-ui.js"></script>
    <script src="https://netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/js/bootstrap.min.js"></script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link href="https://netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/css/bootstrap-combined.min.css" rel="stylesheet">
    
    <link type="text/css" rel="stylesheet" href="https://diffsharp.github.io/DiffSharp/misc/style.css" />
    <script src="https://diffsharp.github.io/DiffSharp/misc/tips.js" type="text/javascript"></script>
  </head>
  <body>
    <div class="container">
      <div class="masthead">
        <ul class="nav nav-pills pull-right">
          <li><a href="https://fsharp.org">fsharp.org</a></li>
        </ul>
        <h3 class="muted">DiffSharp</h3>
      </div>
      <hr />
      <div class="row">
        <div class="span9" id="main">
          <p><a href="https://mybinder.org/v2/gh/dsyme/DiffSharp/gh-pages?filepath=notebooks/examples-topic1.ipynb"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>
<h1><a name="Gradient-Descent" class="anchor" href="#Gradient-Descent">Gradient Descent</a></h1>
<p>The <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent algorithm</a> is an optimization algorithm for finding a local minimum of a scalar-valued function near a starting point, taking successive steps in the direction of the negative of the gradient.</p>
<p>For a function <span class="math">\(f: \mathbb{R}^n \to \mathbb{R}\)</span>, starting from an initial point <span class="math">\(\mathbf{x}_0\)</span>, the method works by computing successive points in the function domain</p>
<p><span class="math">\[ \mathbf{x}_{n + 1} = \mathbf{x}_n - \eta \left( \nabla f \right)_{\mathbf{x}_n} \; ,\]</span></p>
<p>where <span class="math">\(\eta &gt; 0\)</span> is a small step size and <span class="math">\(\left( \nabla f \right)_{\mathbf{x}_n}\)</span> is the <a href="https://en.wikipedia.org/wiki/Gradient">gradient</a> of <span class="math">\(f\)</span> evaluated at <span class="math">\(\mathbf{x}_n\)</span>. The successive values of the function</p>
<p><span class="math">\[ f(\mathbf{x}_0) \ge f(\mathbf{x}_1) \ge f(\mathbf{x}_2) \ge \dots\]</span></p>
<p>keep decreasing and the sequence <span class="math">\(\mathbf{x}_n\)</span> usually converges to a local minimum.</p>
<p>In practice, using a fixed step size <span class="math">\(\eta\)</span> yields suboptimal performance and there are adaptive algorithms that select a locally optimal step size <span class="math">\(\eta\)</span> on each iteration.</p>
<p>The following code implements gradient descent with fixed step size, stopping when the <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">norm</a> of the gradient falls below a given threshold.</p>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="fsharp"><span class="k">open</span> <span onmouseout="hideTip(event, 'fs1', 1)" onmouseover="showTip(event, 'fs1', 1)" class="id">DiffSharp</span>

<span class="c">// Shorthand for dsharp.tensor</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs2', 2)" onmouseover="showTip(event, 'fs2', 2)" class="fn">t</span> <span onmouseout="hideTip(event, 'fs3', 3)" onmouseover="showTip(event, 'fs3', 3)" class="id">x</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs4', 4)" onmouseover="showTip(event, 'fs4', 4)" class="rt">dsharp</span><span class="pn">.</span><span onmouseout="hideTip(event, 'fs5', 5)" onmouseover="showTip(event, 'fs5', 5)" class="id">tensor</span> <span onmouseout="hideTip(event, 'fs3', 6)" onmouseover="showTip(event, 'fs3', 6)" class="id">x</span>

<span class="c">// Gradient descent</span>
<span class="c">//   f: function</span>
<span class="c">//   x0: starting point</span>
<span class="c">//   eta: step size</span>
<span class="c">//   epsilon: threshold</span>
<span class="k">let</span> <span class="k">rec</span> <span onmouseout="hideTip(event, 'fs6', 7)" onmouseover="showTip(event, 'fs6', 7)" class="fn">gradientDescent</span> <span onmouseout="hideTip(event, 'fs7', 8)" onmouseover="showTip(event, 'fs7', 8)" class="fn">f</span> <span onmouseout="hideTip(event, 'fs8', 9)" onmouseover="showTip(event, 'fs8', 9)" class="id">x</span> <span onmouseout="hideTip(event, 'fs9', 10)" onmouseover="showTip(event, 'fs9', 10)" class="id">eta</span> <span onmouseout="hideTip(event, 'fs10', 11)" onmouseover="showTip(event, 'fs10', 11)" class="id">epsilon</span> <span class="o">=</span>
    <span class="k">let</span> <span onmouseout="hideTip(event, 'fs11', 12)" onmouseover="showTip(event, 'fs11', 12)" class="id">g</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs4', 13)" onmouseover="showTip(event, 'fs4', 13)" class="rt">dsharp</span><span class="pn">.</span><span onmouseout="hideTip(event, 'fs12', 14)" onmouseover="showTip(event, 'fs12', 14)" class="id">grad</span> <span onmouseout="hideTip(event, 'fs7', 15)" onmouseover="showTip(event, 'fs7', 15)" class="fn">f</span> <span onmouseout="hideTip(event, 'fs8', 16)" onmouseover="showTip(event, 'fs8', 16)" class="id">x</span>
    <span class="c">// TODO: this should be norm</span>
    <span class="k">if</span> <span onmouseout="hideTip(event, 'fs11', 17)" onmouseover="showTip(event, 'fs11', 17)" class="fn">g</span><span class="pn">.</span><span onmouseout="hideTip(event, 'fs13', 18)" onmouseover="showTip(event, 'fs13', 18)" class="id">sum</span><span class="pn">(</span><span class="pn">)</span> <span class="o">&lt;</span> <span onmouseout="hideTip(event, 'fs10', 19)" onmouseover="showTip(event, 'fs10', 19)" class="id">epsilon</span> <span class="k">then</span> <span onmouseout="hideTip(event, 'fs8', 20)" onmouseover="showTip(event, 'fs8', 20)" class="id">x</span> 
    <span class="k">else</span> <span onmouseout="hideTip(event, 'fs6', 21)" onmouseover="showTip(event, 'fs6', 21)" class="fn">gradientDescent</span> <span onmouseout="hideTip(event, 'fs7', 22)" onmouseover="showTip(event, 'fs7', 22)" class="fn">f</span> <span class="pn">(</span><span onmouseout="hideTip(event, 'fs8', 23)" onmouseover="showTip(event, 'fs8', 23)" class="id">x</span> <span class="o">-</span> <span onmouseout="hideTip(event, 'fs9', 24)" onmouseover="showTip(event, 'fs9', 24)" class="id">eta</span> <span class="o">*</span> <span onmouseout="hideTip(event, 'fs11', 25)" onmouseover="showTip(event, 'fs11', 25)" class="id">g</span><span class="pn">)</span> <span onmouseout="hideTip(event, 'fs9', 26)" onmouseover="showTip(event, 'fs9', 26)" class="id">eta</span> <span onmouseout="hideTip(event, 'fs10', 27)" onmouseover="showTip(event, 'fs10', 27)" class="id">epsilon</span>
</code></pre></td>
</tr>
</table>
<p>Let's find a minimum of <span class="math">\(f(x, y) = (\sin x + \cos y)\)</span>.</p>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l">1: </span>
<span class="l">2: </span>
<span class="l">3: </span>
<span class="l">4: </span>
<span class="l">5: </span>
<span class="l">6: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="fsharp"><span class="k">let</span> <span class="k">inline</span> <span onmouseout="hideTip(event, 'fs14', 28)" onmouseover="showTip(event, 'fs14', 28)" class="fn">f</span> <span class="pn">(</span><span onmouseout="hideTip(event, 'fs8', 29)" onmouseover="showTip(event, 'fs8', 29)" class="id">x</span><span class="pn">:</span><span onmouseout="hideTip(event, 'fs15', 30)" onmouseover="showTip(event, 'fs15', 30)" class="rt">Tensor</span><span class="pn">)</span> <span class="o">=</span>  <span onmouseout="hideTip(event, 'fs16', 31)" onmouseover="showTip(event, 'fs16', 31)" class="fn">sin</span> <span onmouseout="hideTip(event, 'fs8', 32)" onmouseover="showTip(event, 'fs8', 32)" class="id">x</span><span class="pn">.</span><span class="pn">[</span><span class="n">0</span><span class="pn">]</span> <span class="o">+</span> <span onmouseout="hideTip(event, 'fs17', 33)" onmouseover="showTip(event, 'fs17', 33)" class="fn">cos</span> <span onmouseout="hideTip(event, 'fs8', 34)" onmouseover="showTip(event, 'fs8', 34)" class="id">x</span><span class="pn">.</span><span class="pn">[</span><span class="n">1</span><span class="pn">]</span>

<span class="c">// Find the minimum of f</span>
<span class="c">// Start from (1, 1), step size 0.9, threshold 0.00001</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs18', 35)" onmouseover="showTip(event, 'fs18', 35)" class="id">xmin</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs6', 36)" onmouseover="showTip(event, 'fs6', 36)" class="fn">gradientDescent</span> <span onmouseout="hideTip(event, 'fs14', 37)" onmouseover="showTip(event, 'fs14', 37)" class="fn">f</span> <span class="pn">(</span><span onmouseout="hideTip(event, 'fs2', 38)" onmouseover="showTip(event, 'fs2', 38)" class="fn">t</span> <span class="pn">[</span><span class="n">1.</span><span class="pn">;</span> <span class="n">1.</span><span class="pn">]</span><span class="pn">)</span> <span class="pn">(</span><span onmouseout="hideTip(event, 'fs2', 39)" onmouseover="showTip(event, 'fs2', 39)" class="fn">t</span> <span class="n">0.9</span><span class="pn">)</span> <span class="pn">(</span><span onmouseout="hideTip(event, 'fs2', 40)" onmouseover="showTip(event, 'fs2', 40)" class="fn">t</span> <span class="n">0.00001</span><span class="pn">)</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs19', 41)" onmouseover="showTip(event, 'fs19', 41)" class="id">fxmin</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs14', 42)" onmouseover="showTip(event, 'fs14', 42)" class="fn">f</span> <span onmouseout="hideTip(event, 'fs18', 43)" onmouseover="showTip(event, 'fs18', 43)" class="id">xmin</span>
</code></pre></td>
</tr>
</table>
<table class="pre"><tr><td><pre><code>val xmin : Tensor = tensor [ -1.570790759; 3.141591964 ]
val fxmin : Tensor = tensor -2.0</code></pre></td></tr></table>
<p>A minimum, <span class="math">\(f(x, y) = -2\)</span>, is found at <span class="math">\((x, y) = \left(-\frac{\pi}{2}, \pi\right)\)</span>.</p>

          <div class="tip" id="fs1">namespace DiffSharp</div>
<div class="tip" id="fs2">val t : x:&#39;a -&gt; Tensor</div>
<div class="tip" id="fs3">val x : &#39;a</div>
<div class="tip" id="fs4">type dsharp = DiffSharp</div>
<div class="tip" id="fs5">static member DiffSharp.tensor : value:obj * ?dtype:Dtype * ?device:Device * ?backend:Backend -&gt; Tensor</div>
<div class="tip" id="fs6">val gradientDescent : f:(Tensor -&gt; Tensor) -&gt; x:Tensor -&gt; eta:Tensor -&gt; epsilon:Tensor -&gt; Tensor</div>
<div class="tip" id="fs7">val f : (Tensor -&gt; Tensor)</div>
<div class="tip" id="fs8">val x : Tensor</div>
<div class="tip" id="fs9">val eta : Tensor</div>
<div class="tip" id="fs10">val epsilon : Tensor</div>
<div class="tip" id="fs11">val g : Tensor</div>
<div class="tip" id="fs12">static member DiffSharp.grad : f:(Tensor -&gt; Tensor) -&gt; x:Tensor -&gt; Tensor</div>
<div class="tip" id="fs13">member Tensor.sum : ?dtype:Dtype -&gt; Tensor<br />member Tensor.sum : dim:int * ?keepDim:bool * ?dtype:Dtype -&gt; Tensor</div>
<div class="tip" id="fs14">val f : x:Tensor -&gt; Tensor</div>
<div class="tip" id="fs15">Multiple items<br />union case Tensor.Tensor: primalRaw: Backends.RawTensor -&gt; Tensor<br /><br />--------------------<br />type Tensor =<br />&#160;&#160;| Tensor of primalRaw: RawTensor<br />&#160;&#160;| TensorF of primal: Tensor * derivative: Tensor * nestingTag: uint32<br />&#160;&#160;| TensorR of primal: Tensor * derivative: Tensor ref * parentOp: TensorOp * fanout: uint32 ref * nestingTag: uint32<br />&#160;&#160;&#160;&#160;interface IConvertible<br />&#160;&#160;&#160;&#160;interface IEnumerable<br />&#160;&#160;&#160;&#160;interface IEnumerable&lt;Tensor&gt;<br />&#160;&#160;&#160;&#160;interface IEquatable&lt;Tensor&gt;<br />&#160;&#160;&#160;&#160;interface IComparable<br />&#160;&#160;&#160;&#160;override Equals : other:obj -&gt; bool<br />&#160;&#160;&#160;&#160;override GetHashCode : unit -&gt; int<br />&#160;&#160;&#160;&#160;member GetSlice : i0:int -&gt; Tensor<br />&#160;&#160;&#160;&#160;member private GetSlice : bounds:int [,] -&gt; Tensor<br />&#160;&#160;&#160;&#160;member GetSlice : i0:int * i1:int -&gt; Tensor<br />&#160;&#160;&#160;&#160;...</div>
<div class="tip" id="fs16">val sin : value:&#39;T -&gt; &#39;T (requires member Sin)</div>
<div class="tip" id="fs17">val cos : value:&#39;T -&gt; &#39;T (requires member Cos)</div>
<div class="tip" id="fs18">val xmin : Tensor</div>
<div class="tip" id="fs19">val fxmin : Tensor</div>
<div class="tip" id="fs20">val printf : format:Printf.TextWriterFormat&lt;&#39;T&gt; -&gt; &#39;T</div>
         
        </div>
        <div class="span3">
          <a href="index.html"><img src="img/diffsharp-logo.png" style="width:140px;height:140px;margin:10px 0px 0px 20px;border-style:none;"/></a>

          <ul class="nav nav-list" id="menu">
            <li class="nav-header">DiffSharp</li>
            <li class="divider"></li>
            <li><a href="index.html">Home Page</a></li>
            <li><a href="">GitHub Page</a></li>
            <li><a href="download.html">Download and FAQ</a></li>
            <li><a href="/blob/master/RELEASE_NOTES.md">Release Notes</a></li>

            <li class="nav-header">Getting Started</li>
            <li class="divider"></li>
            <li><a href="api-overview.html">API Overview</a></li>
            <li><a href="gettingstarted-topic1.html">Getting Started Topic 1</a></li>
            <li><a href="reference/index.html">API Reference</a></li>

            <li class="nav-header">Examples</li>
            <li class="divider"></li>

            <li class="nav-header">Machine Learning</li>
            <li><a href="examples-topic1.html">Topic 1</a></li>

            <li class="nav-header">Authors</li>
            <li class="divider"></li>
            <li><a href="http://www.robots.ox.ac.uk/~gunes/">Atılım Güneş Baydin</a></li>
            <li><a href="https://www.bcl.hamilton.ie/~barak/">Barak A. Pearlmutter</a></li>
            <li><a href="https://www.microsoft.com/en-us/research/people/dsyme/">Don Syme</a></li>
          </ul>
        </div>
      </div>
    </div>
  </body>
</html>
